{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "### Predicting Customer Churn"}, {"metadata": {}, "cell_type": "markdown", "source": "### Environment Setup"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "#Uncomment and run once to install the package in your runtime environment\n!pip install pandas_profiling", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Uncomment and run once to install the package in your runtime environment\n!pip install sklearn-pandas", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Uncomment and run once to install the package in your runtime environment\n#!pip install watson-machine-learning-client --upgrade\n!pip install --upgrade watson-machine-learning-client-V4", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nimport pandas_profiling\nimport sklearn.pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, LabelBinarizer, OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, accuracy_score, roc_curve, roc_auc_score\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\nimport json\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Step 1: Load data \n\n#### 1.1: Download the data files"}, {"metadata": {}, "cell_type": "code", "source": "customer_churn = pd.read_csv('/project_data/data_asset/churn.csv')\ncustomer_churn.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "customer = pd.read_csv('/project_data/data_asset/customer-profile.csv')\ncustomer.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Step 2: Merge Files"}, {"metadata": {}, "cell_type": "code", "source": "data = pd.merge(customer, customer_churn, on='ID')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Step 3: Rename some columns\nThis step is to remove spaces from columns names, it's an example of data preparation that you may want to do before creating a model. "}, {"metadata": {}, "cell_type": "code", "source": "data.columns", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "data.rename(columns={'Est Income':'EstIncome', 'Car Owner':'CarOwner' }, inplace=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "data.head()", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "data.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Step 4: Data understanding"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "data.describe()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#pandas_profiling.ProfileReport(data)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Step 5: Build the sklearn pipeline and the Random Forest model\n"}, {"metadata": {}, "cell_type": "code", "source": "# Define input data to the model\nX = data.drop(['ID','CHURN'], axis=1)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Define the target variable and encode with value between 0 and n_classes-1, that is from T/F to 1/0\nle = LabelEncoder()\ny = le.fit_transform(data['CHURN'])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "label_mapping=le.inverse_transform([0,1])\nprint('0: ', label_mapping[0])\nprint('1: ', label_mapping[1])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# split the data to training and testing set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Use the DataFrameMapper class to declare transformations and variable imputations.\n\n* LabelBinarizer - Converts a categorical variable into a dummy variable (aka binary variable)\n* StandardScaler - Standardize features by removing the mean and scaling to unit variance, z = (x - u) / s\n\nSee docs: \n* https://github.com/scikit-learn-contrib/sklearn-pandas\n* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler\n* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer\n* https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"}, {"metadata": {}, "cell_type": "code", "source": "\nmapper_good = DataFrameMapper([\n    (['Gender'], LabelBinarizer()),\n    (['Status'], LabelBinarizer()),\n    (['CarOwner'], LabelBinarizer()),\n    (['Paymethod'], LabelBinarizer()),\n    (['MembershipPlan'], LabelBinarizer()),\n    (['Children'],  StandardScaler()),\n    (['EstIncome'],  StandardScaler()),\n    (['Age'],  StandardScaler()),\n    (['AvgMonthlySpend'],  StandardScaler()),\n    (['CustomerSupportCalls'],  StandardScaler())], default=False)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Instantiate the Classifier\nrandom_forest = RandomForestClassifier(random_state=5)\n\n# Define the steps in the pipeline to sequentially apply a list of transforms and the estimator, i.e. RandomForestClassifier\nsteps = [('mapper', mapper_good),('RandonForestClassifier', random_forest)]\npipeline = sklearn.pipeline.Pipeline(steps)\n\n# train the model\nmodel=pipeline.fit( X_train, y_train )\n\nmodel", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Display Label Mapping to assist with interpretation of the model\nlabel_mapping=le.inverse_transform([0,1])\nprint('0: ', label_mapping[0])\nprint('1: ', label_mapping[1])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "### call pipeline.predict() on your X_test data to make a set of test predictions\ny_prediction = pipeline.predict( X_test )\n\n### test your predictions using sklearn.classification_report()\nreport = sklearn.metrics.classification_report( y_test, y_prediction )\n\n### and print the report\nprint(report)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "###  Step 6:  Tune the model to find the best model"}, {"metadata": {}, "cell_type": "code", "source": "# List keys to the model param to tune\n#model.get_params().keys()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "parameters = { 'RandonForestClassifier__max_depth': [5,8,10],\n               'RandonForestClassifier__n_estimators': [150,180,200]}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "grid_obj = GridSearchCV(estimator=model, param_grid=parameters,  cv=3)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\ngrid_fit = grid_obj.fit(X_train,y_train)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Get the estimator\nbest_clf = grid_fit.best_estimator_", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "best_predictions = best_clf.predict(X_test)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "best_predictions_report = sklearn.metrics.classification_report( y_test, best_predictions )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print('Results of best fitted model: \\n\\n',best_predictions_report)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print('Results of default model: \\n\\n',report)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "m_step=pipeline.named_steps['mapper']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "m_step.transformed_names_", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "features = m_step.transformed_names_", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Get the features importance\nimportances = pipeline.named_steps['RandonForestClassifier'][1].feature_importances_\nindices = np.argsort(importances)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "plt.figure(1)\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b',align='center')\nplt.yticks(range(len(indices)), (np.array(features))[indices])\nplt.xlabel('Relative Importance')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Step 7: Save Model in the Project\n"}, {"metadata": {}, "cell_type": "code", "source": "# specify values for the model_name, model_tag for the model to be saved\nmodel_name = 'customer_churn_model_el'\nmodel_tag = 'customer_churn_model_tag_el'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# get the Project ID and set the location to save the model to the project\nfrom watson_machine_learning_client import WatsonMachineLearningAPIClient\nimport os\n\ntoken = os.environ['USER_ACCESS_TOKEN']\n\nwml_credentials = {\n   \"token\": token,\n   \"instance_id\" : \"wml_local\",\n   \"url\": os.environ['RUNTIME_ENV_APSX_URL'],\n   \"version\": \"2.5.0\"\n}\n\nclient = WatsonMachineLearningAPIClient(wml_credentials)\n\nproject_id = os.environ['PROJECT_ID']\nclient.set.default_project(project_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Provide metadata and save the model into the repository. After running this cell, the model will be displayed in the Assets view\nmetadata = {\n    client.repository.ModelMetaNames.NAME: model_name,\n    client.repository.ModelMetaNames.TYPE: \"scikit-learn_0.20\",\n    client.repository.ModelMetaNames.RUNTIME_UID: \"scikit-learn_0.20-py3\",\n    client.repository.ModelMetaNames.TAGS: [{'value' : model_tag}]\n\n}\n\nstored_model_details = client.repository.store_model(pipeline,\n                                               meta_props=metadata,\n                                               training_data=X_train,\n                                               training_target=y_train)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**In this version of the notebook we will perform deployment steps in the UI.**"}, {"metadata": {}, "cell_type": "markdown", "source": "**Author:**  Sidney Phoon <br/>\n**Date:**  Dec 5th, 2019"}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.8", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}